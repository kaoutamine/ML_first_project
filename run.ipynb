{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df46e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe34a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO move this to a helpers folder and also why was a helper not provided anywhere?\n",
    "def load_csv_data(data_path):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int64) #check if int 64 precision was actually needed\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    return yb, input_data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af41c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40e993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfd3f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Prediction', 'DER_mass_MMC', 'DER_mass_transverse_met_lep',\n",
       "       'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt',\n",
       "       'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi',\n",
       "       'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi',\n",
       "       'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt',\n",
       "       'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt',\n",
       "       'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde5a6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "249995    0\n",
       "249996    0\n",
       "249997    1\n",
       "249998    0\n",
       "249999    0\n",
       "Name: PRI_jet_num, Length: 250000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PRI_jet_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50a8f2",
   "metadata": {},
   "source": [
    "### Code start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e5dc80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "y_train, tX_train, ids_train = load_csv_data(DATA_TRAIN_PATH)\n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0cfa194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data_cleaned = data\n",
    "    \n",
    "    data_cleaned[data_cleaned == -999] = np.NaN\n",
    "    \n",
    "    #replace NaN's by mean of columns\n",
    "    medians = np.nanmedian(data_cleaned, axis=0)\n",
    "    sq_std = np.std(data_cleaned, axis=0) **2\n",
    "    inds = np.where(np.isnan(data_cleaned))\n",
    "    data_cleaned[inds] = np.take(medians, inds[1])\n",
    "    \n",
    "    #standardize the columns \n",
    "    data_cleaned = (data_cleaned - medians)  / sq_std \n",
    "    \n",
    "    \n",
    "    #augment the data \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b6718252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f6bef3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_positives(pred, act):\n",
    "    tot = 0\n",
    "    good = 0\n",
    "    for p,a in zip(pred,act):\n",
    "        if(a == 1.0):\n",
    "            tot += 1\n",
    "            if(p == 1.0):\n",
    "                good += 1\n",
    "    return good / tot\n",
    "                \n",
    "            \n",
    "def real_negatives(pred,act):\n",
    "    tot = 0\n",
    "    good = 0\n",
    "    for p,a in zip(pred,act):\n",
    "        if(a == 0.0):\n",
    "            tot += 1\n",
    "            if(p == 0.0):\n",
    "                good += 1\n",
    "    return good/tot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5fa54953",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(30,)\n",
      "(30,)\n"
     ]
    }
   ],
   "source": [
    "#cleaning the training and test set\n",
    "tX_train_clean = clean_data(tX_train)\n",
    "tX_test_clean = clean_data(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9c87d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into train and validation \n",
    "xTr, xVal, yTr, yVal = split_data(tX_train_clean, y_train, ratio=0.75, seed= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a7f5cd3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train the model on the training set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "7fb9b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3438575819298831\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(yTr, xTr, 0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d5e663fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the precision is :\n",
      "0.519392\n",
      "the real positives are :\n",
      "the real negatives are :\n"
     ]
    }
   ],
   "source": [
    "#predict on the validation set \n",
    "pred = xVal.dot(w)\n",
    "\n",
    "#format the predictions  \n",
    "pred[pred > 0] = 1\n",
    "pred[pred < 0] = -1 \n",
    "\n",
    "#precision \n",
    "errors = np.sum(np.abs((yVal - pred)))\n",
    "\n",
    "\n",
    "#real_positives = real_positives(pred, yVal) \n",
    "#real_negatives = real_negatives(pred, yVal)\n",
    "#TODO: add the F1 score calculation as well\n",
    "print(\"the precision is :\")\n",
    "print(errors / len(yVal))\n",
    "print(\"the real positives are :\")\n",
    "#print(real_positives)\n",
    "print(\"the real negatives are :\")\n",
    "#print(real_negatives)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "4407a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in .csv format for submission to Kaggle or AIcrowd\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, \"w\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1), \"Prediction\": int(r2)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "2e6f0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, pred, \"pred1.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
