{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df46e65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "abe34a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO move this to a helpers folder and also why was a helper not provided anywhere?\n",
    "def load_csv_data(data_path):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int64) #check if int 64 precision was actually needed\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    return yb, input_data, ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af41c4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b40e993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id\n"
     ]
    }
   ],
   "source": [
    "print(df.columns[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cfd3f9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'Prediction', 'DER_mass_MMC', 'DER_mass_transverse_met_lep',\n",
       "       'DER_mass_vis', 'DER_pt_h', 'DER_deltaeta_jet_jet', 'DER_mass_jet_jet',\n",
       "       'DER_prodeta_jet_jet', 'DER_deltar_tau_lep', 'DER_pt_tot', 'DER_sum_pt',\n",
       "       'DER_pt_ratio_lep_tau', 'DER_met_phi_centrality',\n",
       "       'DER_lep_eta_centrality', 'PRI_tau_pt', 'PRI_tau_eta', 'PRI_tau_phi',\n",
       "       'PRI_lep_pt', 'PRI_lep_eta', 'PRI_lep_phi', 'PRI_met', 'PRI_met_phi',\n",
       "       'PRI_met_sumet', 'PRI_jet_num', 'PRI_jet_leading_pt',\n",
       "       'PRI_jet_leading_eta', 'PRI_jet_leading_phi', 'PRI_jet_subleading_pt',\n",
       "       'PRI_jet_subleading_eta', 'PRI_jet_subleading_phi', 'PRI_jet_all_pt'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cde5a6de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         2\n",
       "1         1\n",
       "2         1\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "249995    0\n",
       "249996    0\n",
       "249997    1\n",
       "249998    0\n",
       "249999    0\n",
       "Name: PRI_jet_num, Length: 250000, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['PRI_jet_num']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50a8f2",
   "metadata": {},
   "source": [
    "# Code start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e5dc80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "y_train, tX_train, ids_train = load_csv_data(DATA_TRAIN_PATH)\n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5f37ccf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "54942bc3",
   "metadata": {},
   "source": [
    "### Useful  functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0cfa194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data_cleaned = data\n",
    "    \n",
    "    data_cleaned[data_cleaned == -999] = np.NaN\n",
    "    \n",
    "    #replace NaN's by mean of columns\n",
    "    medians = np.nanmedian(data_cleaned, axis=0)\n",
    "    sq_std = np.std(data_cleaned, axis=0) **2\n",
    "    inds = np.where(np.isnan(data_cleaned))\n",
    "    data_cleaned[inds] = np.take(medians, inds[1])\n",
    "    \n",
    "    #standardize the columns \n",
    "    data_cleaned = (data_cleaned - medians)  / sq_std \n",
    "    \n",
    "    \n",
    "    #augment the data \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6718252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f6bef3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_positives(pred, act):\n",
    "    tot = 0\n",
    "    good = 0\n",
    "    for p,a in zip(pred,act):\n",
    "        if(a == 1.0):\n",
    "            tot += 1\n",
    "            if(p == 1.0):\n",
    "                good += 1\n",
    "    return good / tot\n",
    "                \n",
    "            \n",
    "def real_negatives(pred,act):\n",
    "    tot = 0\n",
    "    good = 0\n",
    "    for p,a in zip(pred,act):\n",
    "        if(a == 0.0):\n",
    "            tot += 1\n",
    "            if(p == 0.0):\n",
    "                good += 1\n",
    "    return good/tot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a45d96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        degree: integer.\n",
    "        \n",
    "    Returns:\n",
    "        poly: numpy array of shape (N,d+1)\n",
    "    \"\"\"\n",
    "    degrees = x\n",
    "    for i in range(degree):\n",
    "        degree_matrix = x**(i+2)\n",
    "        degrees = np.c_[degrees, degree_matrix]\n",
    "        \n",
    "    return degrees\n",
    "\n",
    "def pairwise_column(x):\n",
    "    x_aug = x \n",
    "    for i in range(x.shape[1]):\n",
    "        if i!=1:\n",
    "            x_aug = np.c_[x_aug, np.multiply(x[:, i], x[:,1])]\n",
    "    return x_aug\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8229470f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ad6f2b59",
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_train_aug = build_poly(tX_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8f10d29e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38470e+02,  5.16550e+01,  9.78270e+01,  2.79800e+01,\n",
       "        9.10000e-01,  1.24711e+02,  2.66600e+00,  3.06400e+00,\n",
       "        4.19280e+01,  1.97760e+02,  1.58200e+00,  1.39600e+00,\n",
       "        2.00000e-01,  3.26380e+01,  1.01700e+00,  3.81000e-01,\n",
       "        5.16260e+01,  2.27300e+00, -2.41400e+00,  1.68240e+01,\n",
       "       -2.77000e-01,  2.58733e+02,  2.00000e+00,  6.74350e+01,\n",
       "        2.15000e+00,  4.44000e-01,  4.60620e+01,  1.24000e+00,\n",
       "       -2.47500e+00,  1.13497e+02])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0e4aea78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1.38470000e+02,  5.16550000e+01,  9.78270000e+01,  2.79800000e+01,\n",
       "        9.10000000e-01,  1.24711000e+02,  2.66600000e+00,  3.06400000e+00,\n",
       "        4.19280000e+01,  1.97760000e+02,  1.58200000e+00,  1.39600000e+00,\n",
       "        2.00000000e-01,  3.26380000e+01,  1.01700000e+00,  3.81000000e-01,\n",
       "        5.16260000e+01,  2.27300000e+00, -2.41400000e+00,  1.68240000e+01,\n",
       "       -2.77000000e-01,  2.58733000e+02,  2.00000000e+00,  6.74350000e+01,\n",
       "        2.15000000e+00,  4.44000000e-01,  4.60620000e+01,  1.24000000e+00,\n",
       "       -2.47500000e+00,  1.13497000e+02,  1.91739409e+04,  2.66823903e+03,\n",
       "        9.57012193e+03,  7.82880400e+02,  8.28100000e-01,  1.55528335e+04,\n",
       "        7.10755600e+00,  9.38809600e+00,  1.75795718e+03,  3.91090176e+04,\n",
       "        2.50272400e+00,  1.94881600e+00,  4.00000000e-02,  1.06523904e+03,\n",
       "        1.03428900e+00,  1.45161000e-01,  2.66524388e+03,  5.16652900e+00,\n",
       "        5.82739600e+00,  2.83046976e+02,  7.67290000e-02,  6.69427653e+04,\n",
       "        4.00000000e+00,  4.54747923e+03,  4.62250000e+00,  1.97136000e-01,\n",
       "        2.12170784e+03,  1.53760000e+00,  6.12562500e+00,  1.28815690e+04,\n",
       "        2.65501560e+06,  1.37827887e+05,  9.36216318e+05,  2.19049936e+04,\n",
       "        7.53571000e-01,  1.93960942e+06,  1.89487443e+01,  2.87651261e+01,\n",
       "        7.37076288e+04,  7.73419932e+06,  3.95930937e+00,  2.72054714e+00,\n",
       "        8.00000000e-03,  3.47672719e+04,  1.05187191e+00,  5.53063410e-02,\n",
       "        1.37595880e+05,  1.17435204e+01, -1.40673339e+01,  4.76198232e+03,\n",
       "       -2.12539330e-02,  1.73203025e+07,  8.00000000e+00,  3.06659262e+05,\n",
       "        9.93837500e+00,  8.75283840e-02,  9.77301067e+04,  1.90662400e+00,\n",
       "       -1.51609219e+01,  1.46201944e+06,  3.67640010e+08,  7.11949949e+06,\n",
       "        9.15872337e+07,  6.12901721e+05,  6.85749610e-01,  2.41890631e+08,\n",
       "        5.05173523e+01,  8.81363465e+01,  3.09041346e+06,  1.52951526e+09,\n",
       "        6.26362742e+00,  3.79788380e+00,  1.60000000e-03,  1.13473422e+06,\n",
       "        1.06975374e+00,  2.10717159e-02,  7.10352492e+06,  2.66930219e+01,\n",
       "        3.39585441e+01,  8.01155906e+04,  5.88733944e-03,  4.48133382e+09,\n",
       "        1.60000000e+01,  2.06795673e+07,  2.13675062e+01,  3.88626025e-02,\n",
       "        4.50164418e+06,  2.36421376e+00,  3.75232816e+01,  1.65934820e+08])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train_aug[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fa54953",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the training and test set\n",
    "tX_train_clean = clean_data(tX_train)\n",
    "tX_test_clean = clean_data(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "af20ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding features with polynomial basis function \n",
    "tX_train_clean_poly = build_poly(tX_train_clean, 4)\n",
    "tX_test_clean_poly = build_poly(tX_test_clean, 4)\n",
    "#adding the pairwise multiplication\n",
    "tX_train_clean_pc = pairwise_column(tX_train_clean)\n",
    "tX_test_clean_pc = pairwise_column(tX_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "91f20094",
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_clean_aug = np.c_[tX_test_clean_pc[:,30:], tX_test_clean_poly]\n",
    "tX_train_clean_aug = np.c_[tX_train_clean_pc[:,30:], tX_train_clean_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c3029b9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 59)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train_clean_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5bf36191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 179)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(tX_train_clean_aug.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9c87d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into train and validation \n",
    "xTr, xVal, yTr, yVal = split_data(tX_train_clean_aug, y_train, ratio=0.75, seed= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a7f5cd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187500,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model on the training set \n",
    "yTr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7fb9b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2889176205734921\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(yTr, xTr, 0)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d5e663fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.10836343  0.35903445  0.96014503 ... -1.1217302   0.27259588\n",
      " -0.6263442 ]\n",
      "[-0.01137542  0.03768953  0.10079092 ... -0.11775327  0.02861567\n",
      " -0.06575028]\n",
      "the number of errors : 12396.0\n",
      "the precision is :\n",
      "0.8016639999999999\n",
      "the real positives are :\n",
      "the real negatives are :\n"
     ]
    }
   ],
   "source": [
    "#predict on the validation set \n",
    "pred = xVal.dot(w)\n",
    "print(pred)\n",
    "#format the predictions  \n",
    "pred = (pred )/(pred.max()- pred.min())\n",
    "print(pred)\n",
    "pred[pred > 0] = 1\n",
    "pred[pred < 0] = -1 \n",
    "\n",
    "#precision \n",
    "errors = np.sum(np.abs((yVal - pred)))/2\n",
    "print(\"the number of errors : \"+str(errors))\n",
    "\n",
    "#real_positives = real_positives(pred, yVal) \n",
    "#real_negatives = real_negatives(pred, yVal)\n",
    "#TODO: add the F1 score calculation as well\n",
    "print(\"the precision is :\")\n",
    "print(1- (errors / len(yVal)))\n",
    "print(\"the real positives are :\")\n",
    "#print(real_positives)\n",
    "print(\"the real negatives are :\")\n",
    "#print(real_negatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe2167",
   "metadata": {},
   "source": [
    "## Prediction on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "52248c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.06741461 -0.67981738 -0.1094449  ...  0.29242037 -0.03996507\n",
      " -0.79447477]\n",
      "[-1.33381938e-03 -8.49485846e-04 -1.36760095e-04 ...  3.65402489e-04\n",
      " -4.99395314e-05 -9.92759360e-04]\n",
      "we set everything to 1 or -1\n",
      "[-1. -1. -1. ...  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "pred_test = tX_test_clean_aug.dot(w)\n",
    "print(pred_test)\n",
    "#format the predictions  \n",
    "pred_test = pred_test /(pred_test.max()- pred_test.min())\n",
    "print(pred_test)\n",
    "pred_test[pred_test > 0] = 1\n",
    "pred_test[pred_test < 0] = -1 \n",
    "print(\"we set everything to 1 or -1\")\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4407a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in .csv format for submission to Kaggle or AIcrowd\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, \"w\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1), \"Prediction\": int(r2)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2e6f0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, pred_test, \"pred1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad621187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
