{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "df46e65f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import pandas as pd\n",
    "from implementations import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "abe34a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO move this to a helpers folder and also why was a helper not provided anywhere?\n",
    "def load_csv_data(data_path):\n",
    "    \"\"\"Loads data and returns y (class labels), tX (features) and ids (event ids)\"\"\"\n",
    "    y = np.genfromtxt(data_path, delimiter=\",\", skip_header=1, dtype=str, usecols=1)\n",
    "    x = np.genfromtxt(data_path, delimiter=\",\", skip_header=1)\n",
    "    ids = x[:, 0].astype(np.int64) #check if int 64 precision was actually needed\n",
    "    input_data = x[:, 2:]\n",
    "\n",
    "    # convert class labels from strings to binary (-1,1)\n",
    "    yb = np.ones(len(y))\n",
    "    yb[np.where(y=='b')] = -1\n",
    "\n",
    "    return yb, input_data, ids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc50a8f2",
   "metadata": {},
   "source": [
    "# Code start "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e5dc80f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "\n",
    "DATA_TRAIN_PATH = 'train.csv'\n",
    "DATA_TEST_PATH = 'test.csv'\n",
    "y_train, tX_train, ids_train = load_csv_data(DATA_TRAIN_PATH)\n",
    "y_test, tX_test, ids_test = load_csv_data(DATA_TEST_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54942bc3",
   "metadata": {},
   "source": [
    "### Useful  functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0cfa194b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data):\n",
    "    data_cleaned = data\n",
    "    \n",
    "    data_cleaned[data_cleaned == -999] = np.NaN\n",
    "    \n",
    "    #replace NaN's by mean of columns\n",
    "    medians = np.nanmedian(data_cleaned, axis=0)\n",
    "    sq_std = np.std(data_cleaned, axis=0) **2\n",
    "    inds = np.where(np.isnan(data_cleaned))\n",
    "    data_cleaned[inds] = np.take(medians, inds[1])\n",
    "    \n",
    "    #standardize the columns \n",
    "    data_cleaned = (data_cleaned - medians)  / sq_std \n",
    "    \n",
    "    \n",
    "    #augment the data \n",
    "    \n",
    "    \n",
    "    \n",
    "    return data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b6718252",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(x, y, ratio, seed=1):\n",
    "    \"\"\"split the dataset based on the split ratio.\"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(seed)\n",
    "    # generate random indices\n",
    "    num_row = len(y)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    index_split = int(np.floor(ratio * num_row))\n",
    "    index_tr = indices[: index_split]\n",
    "    index_te = indices[index_split:]\n",
    "    # create split\n",
    "    x_tr = x[index_tr]\n",
    "    x_te = x[index_te]\n",
    "    y_tr = y[index_tr]\n",
    "    y_te = y[index_te]\n",
    "    return x_tr, x_te, y_tr, y_te"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f6bef3c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def real_positives(pred, act):\n",
    "    tot = 0\n",
    "    good = 0\n",
    "    for p,a in zip(pred,act):\n",
    "        if(a == 1.0):\n",
    "            tot += 1\n",
    "            if(p == 1.0):\n",
    "                good += 1\n",
    "    return good / tot\n",
    "                \n",
    "            \n",
    "def real_negatives(pred,act):\n",
    "    tot = 0\n",
    "    good = 0\n",
    "    for p,a in zip(pred,act):\n",
    "        if(a == 0.0):\n",
    "            tot += 1\n",
    "            if(p == 0.0):\n",
    "                good += 1\n",
    "    return good/tot\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a45d96bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_poly(x, degree):\n",
    "    \"\"\"polynomial basis functions for input data x, for j=0 up to j=degree.\n",
    "    Args:\n",
    "        x: numpy array of shape (N,), N is the number of samples.\n",
    "        degree: integer.\n",
    "        \n",
    "    Returns:\n",
    "        poly: numpy array of shape (N,d+1)\n",
    "    \"\"\"\n",
    "    degrees = x\n",
    "    for i in range(degree):\n",
    "        degree_matrix = x**(i+2)\n",
    "        degrees = np.c_[degrees, degree_matrix]\n",
    "        \n",
    "    return degrees\n",
    "\n",
    "def pairwise_column(x):\n",
    "    x_aug = x \n",
    "    for i in range(x.shape[1]):\n",
    "        if i!=1:\n",
    "            x_aug = np.c_[x_aug, np.multiply(x[:, i], x[:,1])]\n",
    "    return x_aug\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8229470f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_k_indices(y, k_fold, seed):\n",
    "    \"\"\"build k indices for k-fold.\n",
    "    \n",
    "    Args:\n",
    "        y:      shape=(N,)\n",
    "        k_fold: K in K-fold, i.e. the fold num\n",
    "        seed:   the random seed\n",
    "\n",
    "    Returns:\n",
    "        A 2D array of shape=(k_fold, N/k_fold) that indicates the data indices for each fold\n",
    "\n",
    "    >>> build_k_indices(np.array([1., 2., 3., 4.]), 2, 1)\n",
    "    array([[3, 2],\n",
    "           [0, 1]])\n",
    "    \"\"\"\n",
    "    num_row = y.shape[0]\n",
    "    interval = int(num_row / k_fold)\n",
    "    np.random.seed(seed)\n",
    "    indices = np.random.permutation(num_row)\n",
    "    k_indices = [indices[k * interval: (k + 1) * interval] for k in range(k_fold)]\n",
    "    return np.array(k_indices)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e4b313a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_validation(y, x, k_indices):\n",
    "    \"\"\"return the loss of ridge regression for a fold corresponding to k_indices\n",
    "    \n",
    "    Args:\n",
    "        y:          shape=(N,)\n",
    "        x:          shape=(N,)\n",
    "        k_indices:  2D array returned by build_k_indices()\n",
    "        k:          scalar, the k-th fold (N.B.: not to confused with k_fold which is the fold nums)\n",
    "        \n",
    "\n",
    "    Returns:\n",
    "            ws - the parameters for each fold \n",
    "            precsions - the precision of each fold \n",
    "            best k - the k-th fold that leads to the best score \n",
    "    >>> cross_validation(np.array([1.,2.,3.,4.]), np.array([6.,7.,8.,9.]), np.array([[3,2], [0,1]]), 1, 2, 3)\n",
    "    (0.019866645527597114, 0.33555914361295175)\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    precisions = []\n",
    "    ws = []\n",
    "    \n",
    "    for k in range(k_indices.shape[0]):\n",
    "        train_folds = np.delete(k_indices, k, axis=0)\n",
    "\n",
    "        train = x[train_folds][0]\n",
    "        y_train = y[train_folds][0]\n",
    "        \n",
    "        w, loss_train = ridge_regression(y_train, train, 0.000001)\n",
    "\n",
    "        test = x[k_indices[k]]\n",
    "        y_test = y[k_indices[k]]\n",
    "        \n",
    "        #do the prediction on the k-th fold \n",
    "        pred = test.dot(w)\n",
    "        \n",
    "        #formating the prediction \n",
    "        \n",
    "        pred = (pred )/(pred.max()- pred.min())\n",
    "        pred[pred > 0] = 1\n",
    "        pred[pred < 0] = -1 \n",
    "\n",
    "        #precision \n",
    "        errors = np.sum(np.abs((y_test - pred)))/2\n",
    "        precision = 1- (errors / len(y_test))\n",
    "        \n",
    "        ws.append(w)\n",
    "        \n",
    "        precisions = np.append(precisions, precision)\n",
    "    \n",
    "    return ws, precisions, np.argmax(precisions)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518c56d1",
   "metadata": {},
   "source": [
    "#### Here we do a cross validation (it returns us various w's, losses and the fold that generates the most precise model )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6955293e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cleaning the training and test set\n",
    "tX_train_clean = clean_data(tX_train)\n",
    "tX_test_clean = clean_data(tX_test)\n",
    "# adding features with polynomial basis function \n",
    "tX_train_clean_poly = build_poly(tX_train_clean, 3)\n",
    "tX_test_clean_poly = build_poly(tX_test_clean, 3)\n",
    "# adding the pairwise multiplication\n",
    "tX_train_clean_pc = pairwise_column(tX_train_clean)\n",
    "tX_test_clean_pc = pairwise_column(tX_test_clean)\n",
    "# mixing it all together \n",
    "tX_test_clean_aug = np.c_[tX_test_clean_pc[:,30:], tX_test_clean_poly]\n",
    "tX_train_clean_aug = np.c_[tX_train_clean_pc[:,30:], tX_train_clean_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ce9313a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 30)\n",
      "(250000, 30)\n",
      "(568238, 120)\n",
      "(568238, 149)\n"
     ]
    }
   ],
   "source": [
    "print(tX_test_clean.shape)\n",
    "print(tX_train_clean.shape)\n",
    "print(tX_test_clean_poly.shape)\n",
    "print(tX_test_clean_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "eb1153a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79552 0.79348 0.80048 0.79672 0.79828 0.79504 0.79672 0.80044 0.8008\n",
      " 0.80064]\n",
      "the mean is0.7978120000000001the std is 0.002554559844669927\n"
     ]
    }
   ],
   "source": [
    "#trying the cross validation \n",
    "k_indices = build_k_indices(y_train, 10, 10)\n",
    "ws, precisions, best_k = cross_validation(y_train, tX_train_clean_aug, k_indices)\n",
    "print(precisions)\n",
    "cross_val_std = np.std(precisions)\n",
    "cross_val_mean = np.mean(precisions)\n",
    "\n",
    "print(\"the mean is\" + str(cross_val_mean) + \"the std is \" + str(cross_val_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "72547ef7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.82216\n",
      "(299,)\n"
     ]
    }
   ],
   "source": [
    "w = ws[best_k]\n",
    "print(precisions[best_k])\n",
    "print(w.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "598982ec",
   "metadata": {},
   "source": [
    "#### Once all the cells above have been run got to the part prediction of the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "ad6f2b59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0017057552688037572\n"
     ]
    }
   ],
   "source": [
    "print(w)\n",
    "\n",
    "#tX_train_aug = build_poly(tX_train, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58fa6ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8f10d29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tX_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "0e4aea78",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tX_train_aug[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07051b12",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5fa54953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7c8f02c",
   "metadata": {},
   "source": [
    "##### Here we do not do the cross validation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a11a5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning the training and test set\n",
    "tX_train_clean = clean_data(tX_train)\n",
    "tX_test_clean = clean_data(tX_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "af20ab28",
   "metadata": {},
   "outputs": [],
   "source": [
    "#adding features with polynomial basis function \n",
    "tX_train_clean_poly = build_poly(tX_train_clean, 5)\n",
    "tX_test_clean_poly = build_poly(tX_test_clean, 5)\n",
    "#adding the pairwise multiplication\n",
    "tX_train_clean_pc = pairwise_column(tX_train_clean)\n",
    "tX_test_clean_pc = pairwise_column(tX_test_clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "91f20094",
   "metadata": {},
   "outputs": [],
   "source": [
    "tX_test_clean_aug = np.c_[tX_test_clean_pc[:,30:], tX_test_clean_poly]\n",
    "tX_train_clean_aug = np.c_[tX_train_clean_pc[:,30:], tX_train_clean_poly]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c3029b9f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(250000, 59)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tX_train_clean_pc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5bf36191",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(250000,)\n",
      "(250000, 209)\n"
     ]
    }
   ],
   "source": [
    "print(y_train.shape)\n",
    "print(tX_train_clean_aug.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9c87d8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#splitting the dataset into train and validation \n",
    "xTr, xVal, yTr, yVal = split_data(tX_train_clean_aug, y_train, ratio=0.75, seed= 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a7f5cd3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(187500,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train the model on the training set \n",
    "yTr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "7fb9b00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.28611428959152935\n"
     ]
    }
   ],
   "source": [
    "w, loss = ridge_regression(yTr, xTr, 0.00001)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3020e0fb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "d5e663fa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'xVal' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_6868/2962997063.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#predict on the validation set\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxVal\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#format the predictions\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m \u001b[1;33m)\u001b[0m\u001b[1;33m/\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m-\u001b[0m \u001b[0mpred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'xVal' is not defined"
     ]
    }
   ],
   "source": [
    "#predict on the validation set \n",
    "pred = xVal.dot(w)\n",
    "print(pred)\n",
    "#format the predictions  \n",
    "pred = (pred )/(pred.max()- pred.min())\n",
    "print(pred)\n",
    "pred[pred > 0] = 1\n",
    "pred[pred < 0] = -1 \n",
    "\n",
    "#precision \n",
    "errors = np.sum(np.abs((yVal - pred)))/2\n",
    "print(\"the number of errors : \"+str(errors))\n",
    "\n",
    "#real_positives = real_positives(pred, yVal) \n",
    "#real_negatives = real_negatives(pred, yVal)\n",
    "#TODO: add the F1 score calculation as well\n",
    "print(\"the precision is :\")\n",
    "print(1- (errors / len(yVal)))\n",
    "print(\"the real positives are :\")\n",
    "#print(real_positives)\n",
    "print(\"the real negatives are :\")\n",
    "#print(real_negatives)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbe2167",
   "metadata": {},
   "source": [
    "## Prediction on the test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "52248c2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.9715329  -0.71737571 -0.02043206 ...  0.15877099 -0.14964181\n",
      " -0.93231669]\n",
      "[-4.34137012e-08 -3.20564901e-08 -9.13022449e-10 ...  7.09480477e-09\n",
      " -6.68686035e-09 -4.16612944e-08]\n",
      "we set everything to 1 or -1\n",
      "[-1. -1. -1. ...  1. -1. -1.]\n"
     ]
    }
   ],
   "source": [
    "pred_test = tX_test_clean_aug.dot(w)\n",
    "print(pred_test)\n",
    "#format the predictions  \n",
    "pred_test = pred_test /(pred_test.max()- pred_test.min())\n",
    "print(pred_test)\n",
    "pred_test[pred_test > 0] = 1\n",
    "pred_test[pred_test < 0] = -1 \n",
    "print(\"we set everything to 1 or -1\")\n",
    "print(pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "4407a6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "def create_csv_submission(ids, y_pred, name):\n",
    "    \"\"\"\n",
    "    Creates an output file in .csv format for submission to Kaggle or AIcrowd\n",
    "    Arguments: ids (event ids associated with each prediction)\n",
    "               y_pred (predicted class labels)\n",
    "               name (string name of .csv output file to be created)\n",
    "    \"\"\"\n",
    "    with open(name, \"w\") as csvfile:\n",
    "        fieldnames = [\"Id\", \"Prediction\"]\n",
    "        writer = csv.DictWriter(csvfile, delimiter=\",\", fieldnames=fieldnames)\n",
    "        writer.writeheader()\n",
    "        for r1, r2 in zip(ids, y_pred):\n",
    "            writer.writerow({\"Id\": int(r1), \"Prediction\": int(r2)})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "2e6f0ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(ids_test, pred_test, \"pred1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad621187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
